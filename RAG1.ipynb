{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a748bf02-4778-4243-a3a0-63f885781f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519fc46c-95d9-4e36-aaf2-cf8da3711d5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.19\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\sivak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: jupyter_ai_magics, langchain-community\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91faa414-05ef-4582-9997-bec87ddaa311",
   "metadata": {},
   "source": [
    "### Python.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca69e7a-dc1d-4914-b8a8-57003fa59c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "#os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d665eab2-8fee-4411-b47d-cb86d765b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading PDF, DOCX and TXT files as LangChain Documents\n",
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "\n",
    "    if extension == '.pdf':\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == '.docx':\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f'Loading {file}')\n",
    "        loader = Docx2txtLoader(file)\n",
    "    elif extension == '.txt':\n",
    "        from langchain.document_loaders import TextLoader\n",
    "        loader = TextLoader(file)\n",
    "    else:\n",
    "        print('Document format is not supported!')\n",
    "        return None\n",
    "\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d80510-f415-4c35-b152-d395987fd174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia\n",
    "def load_from_wikipedia(query, lang='en', load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa5a736-4514-4188-af31-c2696ced1d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1173 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/us_constitution.pdf')\n",
    "#print(data[1].page_content)\n",
    "# print(data[10].metadata)\n",
    "\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "print(f'There are {len(data[20].page_content)} characters in the page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d67f5ef-3b26-4c62-a1fd-088c694e760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_document('files/the_great_gatsby.docx')\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ee3a81-915c-40ca-9adf-d7577232bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sivak\\appdata\\roaming\\python\\python313\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sivak\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml): started\n",
      "  Building wheel for wikipedia (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11785 sha256=da4d21508b85b78ce31cee51ca50d43ee2909c52b696f4a1bc95b918fea40fb8\n",
      "  Stored in directory: c:\\users\\sivak\\appdata\\local\\pip\\cache\\wheels\\79\\1d\\c8\\b64e19423cc5a2a339450ea5d145e7c8eb3d4aa2b150cde33b\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66e6e55f-db8c-43ff-a537-838ec241b545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI, Inc. ist ein US-amerikanisches nicht-börsennotiertes Softwareunternehmen, das sich seit Ende 2015 mit der Erforschung von künstlicher Intelligenz (KI, englisch Artificial Intelligence, AI) beschäftigt. Anfänglich war das Ziel von OpenAI, künstliche Intelligenz auf Open-Source-Basis zu entwickeln. Das Unternehmen wurde vorerst als Non-Profit geführt. 2019 wurde die gewinnorientierte Tochtergesellschaft OpenAI Global, LLC gegründet, in der Microsoft größter Investor ist. OpenAI ist vor allem bekannt für die Entwicklung der generativen vortrainierten Transformer (GPT) – auch generative künstliche Intelligenz, kurz GenAI, bezeichnet – und der daraus abgeleiteten Softwareprodukte wie ChatGPT oder DALL-E.\n",
      "\n",
      "\n",
      "== Geschichte ==\n",
      "\n",
      "\n",
      "=== Gründungsphase und Mission ===\n",
      "Der Gründung von OpenAI im Jahr 2015 ging bereits eine lange Debatte um die Risiken von KI voraus. Die Wissenschaftler Stephen Hawking und Stuart Jonathan Russell etwa hatten Befürchtungen geäußert, wenn künstliche Intelligenz eines Tages die Fähigkeit erlangen könnte, sich selbst zu verbessern, dies zu einer Explosion der Intelligenz führen könnte. Durch die damit einhergehende Überlegenheit der KI sei eine Verdrängung der Spezies Mensch durch superintelligente künstliche Intelligenz denkbar, die keinen menschlichen Wertvorstellungen unterworfen ist.\n",
      "Um Risiken wie diesen bei der Entwicklung künstlicher Intelligenz entgegenzutreten, wurde Open AI, Inc. als Open-Source-Non-Profit-Organisation in der Rechtsform einer Public Charity (501(c), Nonprofit) konzipiert. Damit sollte die Unabhängigkeit der Organisation gegenüber Geldgebern und deren Interessen sichergestellt werden; für die Forschung sollte der Freiraum geschaffen werden, sich auf lange Sicht positiv auf die Gesellschaft auswirken zu können. Die Organisation wollte eine „freie Zusammenarbeit“ mit anderen Institutionen und Forschern ermöglichen, indem sie ihre Patente und Forschungsergebnisse für die Öffentlichkeit zugänglich mache.\n",
      "Gegründet wurde OpenAI von einer Gruppe von KI- und IT-Experten, darunter als bekannteste Personen Sam Altman (zuvor unter anderem bei Y Combinator tätig), Greg Brockman, ehemaliger Chefentwickler von Stripe, der Multiunternehmer Elon Musk und Ilya Sutskever, ein ehemaliger Experte von Google für Maschinelles Lernen. Open AI, Inc. wurde ursprünglich ausschließlich durch Spenden finanziert.\n",
      "Die Initiative hatte von Beginn an sehr prominente Unterstützer mit Reid Hoffman, Mitbegründer von LinkedIn,\n",
      "Peter Thiel, Mitbegründer von PayPal,\n",
      "Jessica Livingston, eine Gründungspartnerin von Y Combinator,\n",
      "Amazon Web Services und\n",
      "Infosys Technologies.\n",
      "Das Unternehmen OpenAI selbst äußerte 2015, dass schwer abzuschätzen sei, wie sehr die Gesellschaft von hochwertiger künstlicher Intelligenz profitieren könnte. Genauso komplex sei zu eruieren, welchen Schaden eine missbräuchliche Verwendung dieser Technologie mit sich bringen könnte. Es sei nicht absehbar, wann künstliche Intelligenz auf dem Niveau sein werde, mit der menschlichen Intelligenz in Konkurrenz zu treten. Der Vorstand von OpenAI sagte 2015, künstliche Intelligenz sei eine Erweiterung des individuellen menschlichen Willens. Damit sollte diese Technologie auch flächendeckend verfügbar und jedem Menschen im gleichen Maße zugänglich sein.\n",
      "Das erklärte Fernziel von OpenAI ist die Entwicklung einer künstlichen allgemeinen Intelligenz (Artificial General Intelligence (AGI)), einer fortgeschrittenen Form der KI, die in der Lage sein soll, intellektuelle Aufgaben nicht nur auf einem menschenähnlichen, sondern potenziell darüber hinaus gehenden Niveau zu bewältigen. Ein Übertreffen der menschlichen Intelligenz durch das auf mehrere Jahrzehnte konzipierte Projekt OpenAI ist für den Vorsitzenden des Unternehmens, Sam Altman, jedenfalls denkbar.\n",
      "Vishal Sikka, 2014 bis 2017 Vorstandsvorsitzender von Infosys, schrieb 2015, es sei wichtig, dass die OpenAI-Forschung „the greater good“ – das Wohl der Allgemeinheit – anstrebe. Cade Metz von Wired sagte, \n"
     ]
    }
   ],
   "source": [
    "#data = load_from_wikipedia('GPT-4', 'de')\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d89b6c-f16a-49fc-91ab-231acdee2fcb",
   "metadata": {},
   "source": [
    "### Chunking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf602849-2da7-4622-beec-bab3623b5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90640f0a-e964-46bf-9c17-8b27e5c545bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    # check prices here: https://openai.com/pricing\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.00002:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06dbde19-4ac6-4fcb-9593-a1de8b7b3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "Maryland six, V irginia ten, North Carolina five, South Carolina five, and \n",
      " Georgia three. \n",
      " When vacancies happen in the Representation from any State, the \n",
      " Executive Authority thereof shall issue W rits of Election to fill such \n",
      " V acancies.\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296899aa-4063-44c8-bd23-90e514b0b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 9842\n",
      "Embedding Cost in USD: 0.000197\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ddf512-cfaa-40fc-81de-7e2b8ecb7c93",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a01e2f66-16a4-4024-a416-0c979709b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    # importing the necessary libraries and initializing the Pinecone client\n",
    "    import pinecone\n",
    "    from langchain_community.vectorstores import Pinecone\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from pinecone import ServerlessSpec\n",
    "\n",
    "    \n",
    "    pc = pinecone.Pinecone()\n",
    "        \n",
    "    embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)  # 512 works as well\n",
    "\n",
    "    # loading from existing index\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        # creating the index and embedding the chunks into the index \n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "\n",
    "        # creating a new index\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536,\n",
    "            metric='cosine',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "        ) \n",
    "        )\n",
    "\n",
    "        # processing the input documents, generating embeddings using the provided `OpenAIEmbeddings` instance,\n",
    "        # inserting the embeddings into the index and returning a new Pinecone vector store object. \n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e8d3d54-f400-433e-b537-161ace825e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pc = pinecone.Pinecone()\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes().names()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pc.delete_index(index_name)\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b623a30-c586-4d19-a07e-dce579b8b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17035b2-ffe3-435e-86fa-9c3799f7742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = 'askadocument'\n",
    "vector_store = insert_or_fetch_embeddings(index_name=index_name, chunks=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a88a1b-036e-4a62-a3dd-6023a8c77106",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef876f87-989c-4c3c-98a1-045555ab10ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q, k=3):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.invoke(q)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e13bbb00-7498-4dad-8184-4cb01a9bae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What about The House of Representatives.translate in japanees', 'result': '衆議院'}\n"
     ]
    }
   ],
   "source": [
    "q = 'What about The House of Representatives.translate in japanees'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb3a02-e6a5-4583-8815-e78682dde97b",
   "metadata": {},
   "source": [
    "### While Loop for Asking Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09f66a84-a195-4dce-b6aa-c9f25614dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question #1:  what is bill of rights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: {'query': 'what is bill of rights', 'result': 'The Bill of Rights refers to the first ten amendments to the United States Constitution. These amendments were added to the Constitution in 1791 to guarantee specific rights and freedoms to the American people. The Bill of Rights includes protections such as freedom of speech, religion, and the right to bear arms.'}\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Question #2:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting ... bye bye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print('Write Quit or Exit to quit.')\n",
    "while True:\n",
    "    q = input(f'Question #{i}: ')\n",
    "    i = i + 1\n",
    "    if q.lower() in ['quit', 'exit']:\n",
    "        print('Quitting ... bye bye!')\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f'\\nAnswer: {answer}')\n",
    "    print(f'\\n {\"-\" * 50} \\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
